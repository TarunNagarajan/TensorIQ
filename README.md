# TensorIQ
TensorIQ is a CPU-optimized quantized inference engine built from scratch in C++. It supports: - INT8 quantization (symmetric/asymmetric) - SIMD-tiled GEMM kernels (AVX2/NEON) - ONNX model parsing for MLPs and ConvNets - Layer-wise runtime execution - Hardware-aware tile tuning and benchmarking
